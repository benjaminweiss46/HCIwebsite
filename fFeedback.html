<!DOCTYPE html>
<html>

<head>
	<title>
		Group 19 HCI
	</title>
	<style>
		ul {
			list-style-type: none;
			margin: 0;
			padding: 0;
			overflow: hidden;
			background-color: #333;
		}

		li {
			float: left;
		}

		li a {
			display: block;
			color: white;
			text-align: center;
			padding: 14px 16px;
			text-decoration: none;
		}

		li a:hover {
			background-color: #111;
		}

		#main {
			margin: auto;
			max-width: 800px;
		}

		#names {
			float: right;
		}

		.testDocs {
			max-width: 600px;
			text-align: center;
			margin: auto;
			border: 3px solid black;
		}
	</style>
</head>

<body>
	<div>
		<ul>
			<li><a href="proposal.html">Proposal</a></li>
			<li><a href="LFP&TP.html">Low Fidelity Prototype & Test Plan</a></li>
			<li><a href="cPrototype.html">Computer Prototype</a></li>
			<li><a href="fFeedback.html">Formative Feedback</a></li>
			<li><a href="alpha.html">Alpha System</a></li>
			<li><a href="">Beta System</a></li>
		</ul>
		<p id=names>Ben Weiss, Glen Xu, and Anthony Anastasopoulos</p>
	</div>
	<div id="main">
		<h1>Formative Feedback</h1>
		<ul>
			<li><a href="#te">Testing</a></li>
			<li><a href="#re">Results</a></li>
			<li><a href="#ob">Observations</a></l>
			<li><a href="#tc">Test Critique</a></li>
			<li><a href="#dc">Design Critique</a></li>
		</ul>
		<h3 id="te">Testing of Group 20</h3>
		<p>Following the parameters set out by group 20 all results were sent to them on online surveys, making it very
			difficult to show the results. The documents pretest survey, post-test survey and data collection sheet
			where
			all done in forms sent to group 20. We have requested these documents from group 20 for proof if they were
			able to provide them you should see them below. Three tests were performed by our group following group 20's
			specifications. <br><br>

			Joe Shlomo: A fake name given for one of our roommates, who was the first test subject. Joe Shlomo is a very
			shy individual, who rarely raises his voice and most definitely does not turn on his camera in class. In
			fact he does not go to many classes as he is afraid a teacher may force him to turn his camera on or speak.
			Only going to lectures when participation is worth marks and in those cases hiding himself best he can. This
			fulfills group 20's request of a target audience of individuals who attend online events but are too shy to
			participate with the current channels. Joe did fill out a consent form for his data though it is omitted for
			obvious privacy concerns.</p>

		Calin Zhang: Calin is a 21-year-old university student studying computer science and mathematics. Calin is also
		doing researches with his machine learning professor. Calin is very intelligent and always full of insights, but
		he chooses to share his thoughts and emotions only to his most intimate friends. As a result, his classmates
		always find him introverted, while in fact he is pretty talkative and funny in front of friends. Calin spends a
		lot of time on video conferences, but he nearly never turns the camera on. Calin is a great fit for the
		specification from Group 20, that he is a "[student] who [needs] video conferences for academic studies", and
		"with social phobia who are shy to show their faces". He represents the second test subject.</p>

		Alex Smith: Alex represents the second test subject, a university student studying economics. Alex isn't very
		social, and prefers not to speak up or get involved in his video calls unless it's absolutely necessary. Between
		his lectures and group project meetings, Alex spends a lot of time in video calls, all of which is spent with
		his camera off. Alex doesn't like to have his camera on for privacy reasons, which lines up with the first
		category in the user population described by group 20.

		<h3 id="re">Results</h3>

		<h4>User 1</h4>
		<h5>Pretest Questionnaire</h5>
		<embed src="Feedback/pre1.pdf" width="800px" height="450px" />
		<h5>Data Collection</h5>
		<embed src="Feedback/data1.pdf" width="800px" height="450px" />
		<h5>Post-test Questionnaire</h5>
		<embed src="Feedback/post1.pdf" width="800px" height="450px" />

		<h4>User 2</h4>
		<h5>Pretest Questionnaire</h5>
		<embed src="Feedback/pre2.pdf" width="800px" height="450px" />
		<h5>Data Collection</h5>
		<embed src="Feedback/data2.pdf" width="800px" height="450px" />
		<h5>Post-test Questionnaire</h5>
		<embed src="Feedback/post2.pdf" width="800px" height="450px" />

		<h4>User 3</h4>
		<h5>Pretest Questionnaire</h5>
		<embed src="Feedback/pre3.pdf" width="800px" height="450px" />
		<h5>Data Collection</h5>
		<embed src="Feedback/data3.pdf" width="800px" height="450px" />
		<h5>Post-test Questionnaire</h5>
		<embed src="Feedback/post3.pdf" width="800px" height="450px" />

		<h3 id="ob">Observations and Analysis</h3>
		<h4>Visualization of Pretest Questionnaire Results</h4>
		<embed type="text/html" src="Feedback/Pre-test questionnaire.htm" width="800" height="450">
		<h4>Visualization of Data Collection Results</h4>
		<embed type="text/html" src="Feedback/Data Collection.htm" width="800" height="450">

		<h5>Search for Rowan Atkinson</h5>

		This task was completed quickly by all the users without any assistance. However, all the users also noticed
		that Rowan Atkinson was the default avatar in the prototype, so they questioned the need to search for him since
		he was already selected. One user also pointed out that the search bar wasn't actually working.

		<h5>Turn the Video Output On/Off</h5>

		This task was also completed within 5 seconds by all the users with no assistance. One of the users noted that
		the response time of the prototype was a bit slow, which prompted them to click the button a second time before
		something happened. Two users also brought up the issue of the lack of feedback that turning the video output
		on/off gives. The suggested improvements were to either include a recording button to show when the output is
		on, or to go to a black screen when it's off instead of keeping the image on the screen.

		<h5>Choose Alan Rickman as the current avatar</h5>

		One of the users struggled with this task, since the pictures used for Alan Rickman didn't all look the same and
		they were confused as to whether or not they switched to the right avatar. Another user also took more than one
		attempt to complete this task, as they first tried to search for Alan Rickman in the search bar. The examiner
		then informed them that the search bar not working was a limitation of the current prototype, so they opted to
		just select him in the panel containing the different avatars. This user was also confused by the different
		looking pictures of Alan Rickman.

		<h5>Choose sad emotion for Alan Rickman</h5>

		All three of the users seemed to struggle a bit with this task compared to the others, seeing as it took each of
		them two attempts to complete. When given this task, all three users first tried to choose the sad emotion by
		clicking on the default emotions panel on the bottom of the screen. After this didn't work, they all managed to
		click on the right button to actually complete the task. They recognized that the task was completed
		successfully when the big image changed to the sad emotion one.

		<h5>Remove and then add Rowan Atkinson from favorites</h5>

		This task had mixed results. One of the users was able to complete it quickly without issue. Another also
		completed it quite quickly, but it took them two tries to get it done. The final user took more than two tries
		and actually required assistance from the examiner. This last user couldn't identify any element to represent a
		"favorite" avatar, so they resorted to clicking random things until the examiner intervened. The second user
		noticed that you couldn't remove/add favorites if the desired avatar wasn't selected.


		<h5>Add a New Avatar</h5>
		All users completed this task on the first attempt, under 5 seconds, with no assistance required. Most users
		commented that the "add avatar" button very quickly, and the task was easy to comprehend and achieve. One of the
		users, however, actually already added a new avatar by accident when he tried to add Rowan from favourites in
		the previous test. Still, he quickly recognized that the task is in fact something he had already achieved.


		<h5>Add a Happy Picture for New Avatar</h5>
		All users completed this task with no assistance required. Most of them spent under 5 seconds. In all cases, the
		user was confused by whether they need to upload a picture from their device, or if the unloading process had
		already done by the prototype automatically. In all cases, the the users asked for clarifications from the
		testers about the purpose and requirements for this test, and it has been explained to all of them, that this
		was a limitation of the prototype, and would be improved in the final product.

		<h5>Set the New Avatar's Newly Added Happy Picture as the Default Happy Picture</h5>
		All users completed this task on the first attempt, under 5 seconds, with no assistance required. Most users
		commented that the "add avatar" button very quickly, and the task was easy to comprehend and achieve. One of the
		users, however, actually already set the added picture as default by accident when he tried to upload the
		picture in the previous test, because he thought the green tick indicated the uploading process being
		successful. Still, he quickly recognized that the task is in fact something he had already achieved. Most users
		questioned about why after they clicking the tick, the picture still did not show up in the "Default Emotions"
		section.

		<h5>Add a New Avatar</h5>
		All users completed this task under 5 seconds, with no assistance required. In all cases, the user noticed the
		red garbage icon quickly, and immediately comprehended it as the symbol for deleting. Most users complemented
		this design for its straightforwardness and simplicity.

		<h5>While Using Mel Gibson's Avatar, Enable Detect Facial Expression Mode</h5>
		This task took most users under 5 seconds to accomplish. All users did not require any help to go to Mel
		Gibson's avatar, but one of the user ask for assistance for enabling the detect mode. All users was unsure about
		whether the outcomes were turning on and off. The fact that after the users clicked the button, nothing but a
		slide show of different pictures were shown confused all users. The users understood the purpose of this test
		after clarifications from the testers.

		<h4>Visualization of Post Test Questionnaire Results</h4>
		<embed type="text/html" src="Feedback/Post Test Questionnaire.htm" width="800" height="450">

		<h3 id="tc">Test Plan Critique</h3>
		<h5>Lack of Tests for Some Usability Goals</h5>
		<p>There were no tests to check on usability goals 1. detecting facial expression must be fast and 2. detecting
			facial expression must be accurate. I am aware this is hard to do since they are impossible to test in a
			Framer prototype. Though if they are your usability goals they need to be tested so many you should have
			chosen another prototype method, like producing a bare bones application in some language so that this
			becomes testable. If these usibility goals were tested or able to be tested <b>match between system and the
				real world</b>
			the heuristic by Nielson could also be adressed. We would know how good the match between the users
			expression and the output
			of the software is.</p>
		<h5>Testing Assumes Long Distance Remote Testing</h5>
		<p>This is fair given the times we are currently living in, though I tested my shy roommate who happened to fall
			into the target demographic. In this situation I had to make some assumptions on how to perform the tests.
			Therefore you should add statements such as, "If in person you may do x instead" or write a completely
			different testing document for in person tests vs long distance tests (though the first method is definitely
			easier).</p>
		<h5>Test Script Improvement</h5>
		<p>The test script never mentions showing the user the user manual first before the test. I realize you
			mentioned they should read it on the website but it should be included in the test script as well. One of my
			teammates even asked if they needed to show their subject the user manual first which is why it most
			definitely should be included in the test script. This would adress the heuristic of <b>help and
				documentation</b>
			the evaluator would know to provide the user manual and the user would have access to detailed help if they
			find
			problems using the software.</p>
		<h5>Context for Test 1</h5>
		<p>Test 1, "Search for Rowan Atkinson" becomes very confusing because Rown Atkinson is already the first option
			in the left hand window and the search bar doesn't yet work. A user looked at me and said, "he's right
			there." It doesn't really test the usability goals of "The software should be convenient to use" because no
			task really needs or can be performed in reference to the search bar. If the test was search for someone
			lower down, who is not immediately accessible it would actually help tell you if users can quickly find a
			certain person from the list, but since Rowan is at the top nothing is really being tested. Solutions could
			be as mentioned change the person the first test refers to, to someone not immediately visible, get the
			search bar to work in the prototype, or instruct evaluators to scroll down so Rowan isn't visible before the
			first test. If you fix the search bar you would be right in line with the heuristic of <b>flexibility and
				efficiency of use</b> as there would be multiple ways to perform the same task, search for a name or
			scroll
			to find it.</p>

		<h5>Inconsistency Among Tests</h5>

		<p>Different parts of the data collection sheet had similar structures, but with slightly different details,
			such
			as some of them asked for all completion time, assistance or not, and number of attempts, while other only
			contained one or two of them. This confused the testers a little bit, because they assumed there are
			slightly
			different purposes of these tests. In the same data collection sheet, the wordings and details should be
			consistent.</p>

		<h5>Asking About "what do you think can be better"</h5>

		<p>In the pre test questionnaire, the question "what do you think can be better" was asked multiples
			times to the users. This is a very bad question in a user interview according to Chucks Liu and
			Steve Jobs. When you ask someone what can be improved, they will have to try to create a new product
			or experience that does not exist yet, which makes the interview much harder. </p>

		<h5> Not Working Tests </h5>
		<p>According to the tests results, mast users complained about the confusion that the
			description of the test document and what the prototype actually achieved to do did
			not match. This made the users wonder whether they did something wrong, or if this
			was simply a restriction of the prototype, and additional clarifications are
			required. Such restrictions should be described and explained in the user manual and
			in the test documents, which would relieve a lot of insecurity and confusion during
			the testing process. </p>



		<h3 id="dc">Design Critique</h3>
		<h5>Possible Change 1</h5>
		<p>To delete a default you have to delete the image in the above avatar window.
			This was a source of confusion
			for the delete default test. You would expect deletion options for defaults
			to be in the defaults window.
			Maybe add a deletion option in the defaults window as well as in the avatar
			window.</p>
		<h5>Possible Change 2</h5>
		<p>For operations such as removing/adding a favourite and deleting a image. You
			actually have to select the item
			you want to perform an operation on before performing the operation. In the
			two tests relating to these
			tasks, test subjects went to the still visible star/trash icons even though
			they weren't selected and tried
			performing the operation and were confused when it did not work. Maybe just
			hide these options unless the
			item is selected or if that doesn't fit with the usability goal of "easy to
			understand" just allow users to
			perform these operations without first selecting the item. If they click on
			the star for example, note that
			they clicked on the star for person x and immediately star that one.</p>
		<h5>Possible Change 3</h5>
		<p>The default set up is a large area for improvement. Selecting a default is as
			easy as clicking on a selected
			picture for one of the emotions. Though this can easily lead to problems.
			What if I want to select a certain
			face but I don't want it as one of my defaults? Instead maybe implement a
			button to select the current
			active face as a default. This refers to the test where a user added an item
			to the defaults and was
			wondering why it only took one click. The user commented I guess,"I just did
			the task." I can only imagine
			the users confusion came from not knowing how it could be so easy, realizing
			it could be a problem if they
			wanted to select an image but didn't want it as a default.</p>
	</div>
</body>

</html>